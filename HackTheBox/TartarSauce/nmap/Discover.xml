<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE nmaprun>
<?xml-stylesheet href="file:///usr/bin/../share/nmap/nmap.xsl" type="text/xsl"?>
<!-- Nmap 7.92 scan initiated Wed May 25 10:23:54 2022 as: nmap -&#45;script discovery -oA nmap/Discover -p- -&#45;min-rate 500 10.129.1.185 -->
<nmaprun scanner="nmap" args="nmap -&#45;script discovery -oA nmap/Discover -p- -&#45;min-rate 500 10.129.1.185" start="1653470634" startstr="Wed May 25 10:23:54 2022" version="7.92" xmloutputversion="1.05">
<scaninfo type="connect" protocol="tcp" numservices="65535" services="1-65535"/>
<verbose level="0"/>
<debugging level="0"/>
<prescript><script id="hostmap-robtex" output="*TEMPORARILY DISABLED* due to changes in Robtex&apos;s API. See https://www.robtex.com/api/"/><script id="targets-asn" output="&#xa;  targets-asn.asn is a mandatory parameter&#xa;"/><script id="http-robtex-shared-ns" output="*TEMPORARILY DISABLED* due to changes in Robtex&apos;s API. See https://www.robtex.com/api/"/></prescript><hosthint><status state="up" reason="unknown-response" reason_ttl="0"/>
<address addr="10.129.1.185" addrtype="ipv4"/>
<hostnames>
</hostnames>
</hosthint>
<host starttime="1653470641" endtime="1653470977"><status state="up" reason="syn-ack" reason_ttl="0"/>
<address addr="10.129.1.185" addrtype="ipv4"/>
<hostnames>
</hostnames>
<ports><extraports state="closed" count="65534">
<extrareasons reason="conn-refused" count="65534" proto="tcp" ports="1-79,81-65535"/>
</extraports>
<port protocol="tcp" portid="80"><state state="open" reason="syn-ack" reason_ttl="0"/><service name="http" method="table" conf="3"/><script id="http-security-headers" output=""></script><script id="http-devframework" output="Couldn&apos;t determine the underlying framework or CMS. Try increasing &apos;httpspider.maxpagecount&apos; value to spider more pages."/><script id="http-sitemap-generator" output="&#xa;  Directory structure:&#xa;    /&#xa;      Other: 1&#xa;  Longest directory structure:&#xa;    Depth: 0&#xa;    Dir: /&#xa;  Total files found (by extension):&#xa;    Other: 1&#xa;"/><script id="http-robots.txt" output="5 disallowed entries &#xa;/webservices/tar/tar/source/ &#xa;/webservices/monstra-3.0.4/ /webservices/easy-file-uploader/ &#xa;/webservices/developmental/ /webservices/phpmyadmin/"/><script id="http-vhosts" output="&#xa;128 names had status 200"/><script id="http-comments-displayer" output="&#xa;Spidering limited to: maxdepth=3; maxpagecount=20; withinhost=10.129.1.185&#xa;    &#xa;    Path: http://10.129.1.185:80/&#xa;    Line number: 563&#xa;    Comment: &#xa;        &lt;!-&#45;Carry on, nothing to see here :D-&#45;&gt;&#xa;"/><script id="http-errors" output="Couldn&apos;t find any error pages."/><script id="http-feed" output="Couldn&apos;t find any feeds."/><script id="http-xssed" output="No previously reported XSS vuln."/><script id="http-useragent-tester" output="&#xa;  Status for browser useragent: 200&#xa;  Allowed User Agents: &#xa;    Mozilla/5.0 (compatible; Nmap Scripting Engine; https://nmap.org/book/nse.html)&#xa;    libwww&#xa;    lwp-trivial&#xa;    libcurl-agent/1.0&#xa;    PHP/&#xa;    Python-urllib/2.5&#xa;    GT::WWW&#xa;    Snoopy&#xa;    MFC_Tear_Sample&#xa;    HTTP::Lite&#xa;    PHPCrawl&#xa;    URI::Fetch&#xa;    Zend_Http_Client&#xa;    http client&#xa;    PECL::HTTP&#xa;    Wget/1.13.4 (linux-gnu)&#xa;    WWW-Mechanize/1.34"><elem key="Status for browser useragent">200</elem>
<table key="Allowed User Agents">
<elem>Mozilla/5.0 (compatible; Nmap Scripting Engine; https://nmap.org/book/nse.html)</elem>
<elem>libwww</elem>
<elem>lwp-trivial</elem>
<elem>libcurl-agent/1.0</elem>
<elem>PHP/</elem>
<elem>Python-urllib/2.5</elem>
<elem>GT::WWW</elem>
<elem>Snoopy</elem>
<elem>MFC_Tear_Sample</elem>
<elem>HTTP::Lite</elem>
<elem>PHPCrawl</elem>
<elem>URI::Fetch</elem>
<elem>Zend_Http_Client</elem>
<elem>http client</elem>
<elem>PECL::HTTP</elem>
<elem>Wget/1.13.4 (linux-gnu)</elem>
<elem>WWW-Mechanize/1.34</elem>
</table>
</script><script id="http-enum" output="&#xa;  /robots.txt: Robots file&#xa;"/><script id="http-title" output="Landing Page"><elem key="title">Landing Page</elem>
</script><script id="http-headers" output="&#xa;  Date: Wed, 25 May 2022 09:25:35 GMT&#xa;  Server: Apache/2.4.18 (Ubuntu)&#xa;  Last-Modified: Wed, 21 Feb 2018 20:31:20 GMT&#xa;  ETag: &quot;2a0e-565becf5ff08d&quot;&#xa;  Accept-Ranges: bytes&#xa;  Content-Length: 10766&#xa;  Vary: Accept-Encoding&#xa;  Connection: close&#xa;  Content-Type: text/html&#xa;  &#xa;  (Request type: HEAD)&#xa;"/><script id="http-date" output="Wed, 25 May 2022 09:25:37 GMT; +1h00m00s from local time."><elem key="date">2022-05-25T10:25:37+00:00</elem>
<elem key="delta">3600.0</elem>
</script><script id="http-referer-checker" output="Couldn&apos;t find any cross-domain scripts."/><script id="http-mobileversion-checker" output="No mobile version detected."/><script id="http-chrono" output="Request times for /; avg: 161.39ms; min: 135.39ms; max: 198.63ms"/></port>
</ports>
<hostscript><script id="fcrdns" output="FAIL (No PTR record)"><table key="&lt;none&gt;">
<elem key="status">fail</elem>
<elem key="reason">No PTR record</elem>
</table>
</script><script id="dns-brute" output="Can&apos;t guess domain of &quot;10.129.1.185&quot;; use dns-brute.domain script argument."/></hostscript><times srtt="46249" rttvar="3506" to="100000"/>
</host>
<runstats><finished time="1653470977" timestr="Wed May 25 10:29:37 2022" summary="Nmap done at Wed May 25 10:29:37 2022; 1 IP address (1 host up) scanned in 342.36 seconds" elapsed="342.36" exit="success"/><hosts up="1" down="0" total="1"/>
</runstats>
</nmaprun>
