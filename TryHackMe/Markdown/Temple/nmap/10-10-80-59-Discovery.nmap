# Nmap 7.93 scan initiated Fri Jan 13 20:40:46 2023 as: nmap --script discovery -oA nmap/10-10-80-59-Discovery --min-rate 100 -e tun0 -p 7,22,23,21,61337,80 10.10.80.59
Pre-scan script results:
|_hostmap-robtex: *TEMPORARILY DISABLED* due to changes in Robtex's API. See https://www.robtex.com/api/
| targets-sniffer: Sniffed 1 address(es). 
|_10.10.80.59
|_lltd-discovery: false
|_mrinfo: ERROR: Script execution failed (use -d to debug)
| targets-asn: 
|_  targets-asn.asn is a mandatory parameter
|_http-robtex-shared-ns: *TEMPORARILY DISABLED* due to changes in Robtex's API. See https://www.robtex.com/api/
|_broadcast-pim-discovery: ERROR: Script execution failed (use -d to debug)
|_broadcast-ping: false
|_broadcast-igmp-discovery: ERROR: Script execution failed (use -d to debug)
Nmap scan report for 10.10.80.59
Host is up (0.075s latency).

Bug in http-security-headers: no string output.
PORT      STATE SERVICE
7/tcp     open  echo
21/tcp    open  ftp
|_banner: 220 (vsFTPd 3.0.3)
22/tcp    open  ssh
|_banner: SSH-2.0-OpenSSH_7.6p1 Ubuntu-4ubuntu0.5
| ssh-hostkey: 
|   2048 9e30c56192841b246486c33bb7dc9934 (RSA)
|   256 78c3c3838173cbf15041f19ad7bf3ed1 (ECDSA)
|_  256 ecceb8f957535663e961901215e5784a (ED25519)
| ssh2-enum-algos: 
|   kex_algorithms: (10)
|   server_host_key_algorithms: (5)
|   encryption_algorithms: (6)
|   mac_algorithms: (10)
|_  compression_algorithms: (2)
23/tcp    open  telnet
|_banner: \xFF\xFD\x18\xFF\xFD \xFF\xFD#\xFF\xFD'
| telnet-encryption: 
|_  Telnet server does not support encryption
80/tcp    open  http
|_http-xssed: ERROR: Script execution failed (use -d to debug)
| http-headers: 
|   Date: Fri, 13 Jan 2023 20:41:25 GMT
|   Server: Apache/2.4.29 (Ubuntu)
|   Last-Modified: Sat, 24 Jul 2021 16:44:51 GMT
|   ETag: "2aa6-5c7e13d2f159f"
|   Accept-Ranges: bytes
|   Content-Length: 10918
|   Vary: Accept-Encoding
|   Connection: close
|   Content-Type: text/html
|   
|_  (Request type: HEAD)
|_http-referer-checker: Couldn't find any cross-domain scripts.
|_http-devframework: Couldn't determine the underlying framework or CMS. Try increasing 'httpspider.maxpagecount' value to spider more pages.
|_http-date: Fri, 13 Jan 2023 20:41:24 GMT; +1h00m00s from local time.
| http-vhosts: 
| 126 names had status 200
| mx0
|_mail
| http-comments-displayer: 
| Spidering limited to: maxdepth=3; maxpagecount=20; withinhost=10.10.80.59
|     
|     Path: http://10.10.80.59:80/
|     Line number: 4
|     Comment: 
|         <!--
|             Modified from the Debian original for Ubuntu
|             Last updated: 2016-11-16
|             See: https://launchpad.net/bugs/1288690
|           -->
|     
|     Path: http://10.10.80.59:80/
|     Line number: 201
|     Comment: 
|         <!--      <div class="table_of_contents floating_element">
|                 <div class="section_header section_header_grey">
|                   TABLE OF CONTENTS
|                 </div>
|                 <div class="table_of_contents_item floating_element">
|                   <a href="#about">About</a>
|                 </div>
|                 <div class="table_of_contents_item floating_element">
|                   <a href="#changes">Changes</a>
|                 </div>
|                 <div class="table_of_contents_item floating_element">
|                   <a href="#scope">Scope</a>
|                 </div>
|                 <div class="table_of_contents_item floating_element">
|                   <a href="#files">Config files</a>
|                 </div>
|               </div>
|_        -->
| http-useragent-tester: 
|   Status for browser useragent: 200
|   Allowed User Agents: 
|     Mozilla/5.0 (compatible; Nmap Scripting Engine; https://nmap.org/book/nse.html)
|     libwww
|     lwp-trivial
|     libcurl-agent/1.0
|     PHP/
|     Python-urllib/2.5
|     GT::WWW
|     Snoopy
|     MFC_Tear_Sample
|     HTTP::Lite
|     PHPCrawl
|     URI::Fetch
|     Zend_Http_Client
|     http client
|     PECL::HTTP
|     Wget/1.13.4 (linux-gnu)
|_    WWW-Mechanize/1.34
|_http-chrono: Request times for /; avg: 271.10ms; min: 248.31ms; max: 309.69ms
| http-errors: 
| Spidering limited to: maxpagecount=40; withinhost=10.10.80.59
|   Found the following error pages: 
|   
|   Error Code: 404
|_  	http://10.10.80.59:80/manual
|_http-title: Apache2 Ubuntu Default Page: It works
| http-sitemap-generator: 
|   Directory structure:
|     /
|       Other: 1
|     /icons/
|       png: 1
|   Longest directory structure:
|     Depth: 1
|     Dir: /icons/
|   Total files found (by extension):
|_    Other: 1; png: 1
|_http-mobileversion-checker: No mobile version detected.
| http-grep: 
|   (1) http://10.10.80.59:80/manual: 
|     (1) ip: 
|_      + 10.10.80.59
|_http-feed: Couldn't find any feeds.
61337/tcp open  unknown

Host script results:
| qscan: 
| PORT   FAMILY  MEAN (us)  STDDEV    LOSS (%)
| 7      0       85767.70   16633.63  0.0%
| 21     0       78135.60   9816.85   0.0%
| 22     0       76409.70   11709.60  0.0%
| 23     1       68383.78   12030.37  10.0%
| 80     0       74726.30   15244.54  0.0%
|_61337  0       77866.40   14798.36  0.0%
|_ipidseq: All zeros
|_dns-brute: Can't guess domain of "10.10.80.59"; use dns-brute.domain script argument.
|_fcrdns: FAIL (No PTR record)
|_path-mtu: PMTU == 1500

# Nmap done at Fri Jan 13 20:55:19 2023 -- 1 IP address (1 host up) scanned in 873.11 seconds
